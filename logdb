#!/usr/bin/env python3
import argparse
import base64
import json
import requests


def _sizeof_fmt(num, suffix='B'):
    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:
        if abs(num) < 1024.0:
            return "%3.1f%s%s" % (num, unit, suffix)
        num /= 1024.0
    return "%.1f%s%s" % (num, 'Yi', suffix)


class LogDB:
    def __init__(self, logdb_url, output_json=False):
        self.url = logdb_url
        self.json = output_json
        self.session = requests.Session()

    def _api_url(self, path):
        return f'{self.url}/api/v1{path}'

    def log_status(self, log_id):
        try:
            r = self.session.get(self._api_url(f'/log/{log_id}/status'))
            r.raise_for_status()
            rj = r.json()
            if self.json:
                print(json.dumps(rj))
            else:
                print(json.dumps(rj))
        except requests.exceptions.ConnectionError:
            if self.json:
                print(json.dumps({'error': 'connection error'}))
            else:
                print('ERROR: connection error')

    def status(self):
        try:
            r = self.session.get(self._api_url('/status'))
            r.raise_for_status()
            rj = r.json()
            if self.json:
                print(json.dumps(rj))
            else:
                if rj['healthy']:
                    print('Cluster is healthy')
                else:
                    print('Cluster is NOT healthy!!')
        except requests.exceptions.ConnectionError:
            if self.json:
                print(json.dumps({'error': 'connection error'}))
            else:
                print('ERROR: connection error')

    def list_logs(self):
        r = self.session.get(self._api_url('/logs'))
        r.raise_for_status()
        rj = r.json()
        if self.json:
            print(json.dumps(rj))
        else:
            print('log_name\treplicas')
            for log in rj:
                replicas = str(len(rj[log]['replicas'])) + '/2'
                print(f'{log}\t\t{replicas}')

    def list_nodes(self):
        r = self.session.get(self._api_url('/nodes'))
        r.raise_for_status()
        rj = r.json()
        if self.json:
            print(json.dumps(rj))
        else:
            print('node\t\tdisk space\treadonly')
            for node in rj:
                disk_space = _sizeof_fmt(rj[node]['disk_space'])
                readonly = rj[node]['readonly']
                print(f'{node}\t\t{disk_space}\t\t{readonly}')

    def upload(self, file, log_id):
        r = self.session.post(self._api_url(f'/log/{log_id}'), files={'file': file})
        r.raise_for_status()
        print('ok')

    def query(self, log_id, filters):
        filters_str = ''
        if filters:
            filters_str = '?filters=' + b','.join(base64.b64encode(f.encode()) for f in filters).decode()
        r = self.session.get(self._api_url(f'/log/{log_id}/query{filters_str}'))
        r.raise_for_status()
        rj = r.json()
        if self.json:
            print(json.dumps(rj))
        else:
            print(rj['log_lines'])


def start(args):
    logdb = LogDB(args.logdb_url, args.output == 'json')
    if args.task == 'status':
        logdb.status()
    elif args.task == 'log':
        logdb.log_status(args.log_id)
    elif args.task == 'logs':
        logdb.list_logs()
    elif args.task == 'nodes':
        logdb.list_nodes()
    elif args.task == 'upload':
        logdb.upload(args.file, args.log_id)
    elif args.task == 'query':
        logdb.query(args.log_id, args.filter or [])
    else:
        raise NotImplementedError()


if __name__ == '__main__':
    ap = argparse.ArgumentParser(prog='logdb')
    ap.add_argument('--logdb-url', default='http://127.0.0.1:8080')
    ap.add_argument('-o', '--output', choices=('text', 'json'), default='text')
    subparsers = ap.add_subparsers(dest='task')
    subparsers.required = True
    status_parser = subparsers.add_parser('status')
    log_status_parser = subparsers.add_parser('log')
    log_status_parser.add_argument('log_id')
    logs_parser = subparsers.add_parser('logs')
    nodes_parser = subparsers.add_parser('nodes')
    upload_parser = subparsers.add_parser('upload')
    upload_parser.add_argument('file', type=argparse.FileType('r'), help='File to upload')
    upload_parser.add_argument('log_id', help='Log identifier')
    query_parser = subparsers.add_parser('query')
    query_parser.add_argument('-f', '--filter', action='append')
    query_parser.add_argument('log_id', help='Log identifier')
    args = ap.parse_args()
    start(args)
